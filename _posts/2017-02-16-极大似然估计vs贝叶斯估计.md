**贝叶斯推断**：

- 频率学角度：
  - 假设存在固定但未知的参数$$\theta$$
  - 用已观察到的事实估计$$\theta$$
  - 使用估计的$$\theta$$做预测
- 贝叶斯角度：
  - 表达关于未知参数$$\theta$$的不确定性
  - 使用概率量化不确定性
    - 将未知参数视为**随机变量**
  - 运用概率论规律进行预测
    - 取未知参数的期望值





对于数据集$$D$$，存在一组参数最优$$\theta$$用以描述$$D$$。

可使用贝叶斯法则来对参数$$\theta$$进行推断：

$$ p(\theta | D) = \frac{p(D|\theta) * p(\theta)}{\int_\theta p(D|\theta) * p(\theta)d(\theta)}= \frac{p(D|\theta) * p(\theta)}{p(D)}$$

即 $$posterior = \frac{likelihood * prior}{evidence}$$



**极大似然估计** ：在极大似然估计中，我们寻找最大化似然函数
$$p(D|\theta)$$的点$$\theta$$，将其标注为$$\hat{\theta}$$。注意，这里$$\hat{\theta}$$是一个点，不是随机变量。


换句话说，极大似然估计法将$$ \frac{p(\theta)}{p(D)}​ $$ ($$\frac{prior}{evidence}​$$)视为一个常量，并不允许我们将自己对于参数$$\theta​$$的先验知识$$p(\theta)​$$带入计算中。（或者可以认为我们对于$$\theta​$$的出现做了等概率的假设）

**贝叶斯估计**：相反的，贝叶斯估计将所有的后验分布
$$p(\theta|D) $$全都计算了。贝叶斯推断中，将$$\theta$$视为随机变量。与最大似然估计不同的是，在贝叶斯估计中，我们输入一个概率密度函数，并得到一个概率密度函数（关于参数$$\theta$$的概率分布），而不是一个MLE中的单点。

对于所获得的分布
$$p(\theta|D)$$中所有可能的$$\theta$$，我们需要合理地选择最可能的值。例如，在分布的协方差（或方差）较小的情况下，我们可以使用$$\theta$$的期望。从后验分布中得到的方差，使我们可以表示我们对所选择估计值的信心。如果方差过大，我们甚至可以得出无法获得较好的$$\theta$$估计值的结论。



 用一个简答的例子来再总结一下。 比如你是班里的班长，你有个问题想知道答案，你可以问所有的班里的学生。 一种方案是，问一个学习最好的同学。 另一种方案是，问所有的同学，然后把答案综合起来，但综合的时候，会按照每个同学的成绩好坏来做个权重。 第一种方案的思想类似于ML,MAP，第二种方案类似于贝叶斯模型。





小总结，最大似然是对点估计，贝叶斯是对分布估计。即，假设求解参数$$\theta$$，最大似然是求出最有可能的$$\theta$$值，而贝叶斯则是求解$$\theta$$的分布
